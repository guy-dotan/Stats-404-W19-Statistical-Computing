{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "     File name: hw3_prelim_model.py\n",
    "     Author: Guy Dotan\n",
    "     Date: 02/11/2019\n",
    "     Course: UCLA Stats 404\n",
    "     Description: HW #3. Preliminary model to predict _____ from _____.\n",
    " '''\n",
    "\n",
    "from collections import Counter\n",
    "import inspect\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, \\\n",
    "                            mean_squared_error, roc_auc_score\n",
    "import os\n",
    "\n",
    "\n",
    "path = 'social-power-nba/'\n",
    "df = pd.read_csv(path + \"nba_2017_players_with_salary_wiki_twitter.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullset = df.dropna(subset=['TWITTER_FAVORITE_COUNT'], inplace=True)\n",
    "\n",
    "\n",
    "Counter(df['TWITTER_RETWEET_COUNT'])\n",
    "\n",
    "fulldata = df[np.isfinite(df['TWITTER_RETWEET_COUNT'])]\n",
    "\n",
    "# calculate a 5-number summary\n",
    "# generate data sample\n",
    "data = fulldata['TWITTER_RETWEET_COUNT']\n",
    "# calculate quartiles\n",
    "quartiles = np.percentile(data, [25, 50, 75])\n",
    "# calculate min/max\n",
    "data_min, data_max = data.min(), data.max()\n",
    "# print 5-number summary\n",
    "print('Min: %.3f' % data_min)\n",
    "print('Q1: %.3f' % quartiles[0])\n",
    "print('Median: %.3f' % quartiles[1])\n",
    "print('Q3: %.3f' % quartiles[2])\n",
    "print('Max: %.3f' % data_max)\n",
    "\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "notebook_dir\n",
    "\n",
    "#df = pd.DataFrame({'Age': [99, 53, 71, 84, 84],\n",
    "#                   'Age_units': ['Y', 'Y', 'Y', 'Y', 'Y']})\n",
    "\n",
    "bins = [0, 10, 50, 150, 3000]\n",
    "names = ['<10', '10-49', '50-149', '300+']\n",
    "d = dict(enumerate(names, 1))\n",
    "\n",
    "nba = fulldata\n",
    "\n",
    "nba['TWEET_CAT'] = np.vectorize(d.get)(np.digitize(fulldata['TWITTER_RETWEET_COUNT'], bins))\n",
    "\n",
    "Counter(nba['TWEET_CAT'])\n",
    "\n",
    "print(d)\n",
    "\n",
    "nba.columns\n",
    "\n",
    "\n",
    "df_train, df_valid = train_test_split(nba,\n",
    "                                      test_size=0.25,\n",
    "                                      random_state=2019,\n",
    "                                      stratify=nba['TWEET_CAT'])\n",
    "\n",
    "\n",
    "df_train['TWEET_CAT'].value_counts(sort=True)\n",
    "df_valid['TWEET_CAT'].value_counts(sort=True)\n",
    "\n",
    "\n",
    "\n",
    "y = df_train['TWEET_CAT']\n",
    "X = df_train[['AGE','WINS_RPM','SALARY_MILLIONS','W', 'ORPM', 'DRPM','PIE']]\n",
    "\n",
    "#X = df_train.drop(columns=['Rk', 'Unnamed: 0', 'PLAYER', 'POSITION', 'PAGEVIEWS',\n",
    "#                           'TWITTER_FAVORITE_COUNT','TWITTER_RETWEET_COUNT', 'TEAM', 'TWEET_CAT'])\n",
    "\n",
    "X.shape\n",
    "X.columns\n",
    "\n",
    "X.isna().any()\n",
    "\n",
    "#X[['3P%','FT%']] = X[['3P%','FT%']].fillna(0)\n",
    "\n",
    "### --- Step 1: Specify different number of trees in forest, to determine\n",
    "###             how many to use based on leveling-off of OOB error:\n",
    "n_trees = [50, 100, 250, 500, 1000, 1500, 2500]\n",
    "\n",
    "\n",
    "### --- Step 2: Create dictionary to save-off each estimated RF model:\n",
    "rf_dict = dict.fromkeys(n_trees)\n",
    "\n",
    "\n",
    "for num in n_trees:\n",
    "    print(num)\n",
    "    ### --- Step 3: Specify RF model to estimate:\n",
    "    rf = RandomForestClassifier(n_estimators=num,\n",
    "                                min_samples_leaf=30,\n",
    "                                oob_score=True,\n",
    "                                random_state=2019,\n",
    "                                class_weight='balanced',\n",
    "                                verbose=1)\n",
    "    ### --- Step 4: Estimate RF model and save estimated model:\n",
    "    rf.fit(X, y)\n",
    "    rf_dict[num] = rf\n",
    "\n",
    "\n",
    "### --- Save-off model:\n",
    "# Specify location and name of object to contain estimated model:\n",
    "model_object_path = os.path.join(notebook_dir, 'rf.joblib')\n",
    "# Save estimated model to specified location:\n",
    "dump(rf_dict, model_object_path) \n",
    "\n",
    "# Load model:\n",
    "# rf_dict = load(model_object_path) \n",
    "\n",
    "\n",
    "\n",
    "# Compute OOB error per\n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "oob_error_list = [None] * len(n_trees)\n",
    "\n",
    "# Find OOB error for each forest size:\n",
    "for i in range(len(n_trees)):\n",
    "    oob_error_list[i] = 1 - rf_dict[n_trees[i]].oob_score_\n",
    "else:\n",
    "    # Visulaize result:\n",
    "    plt.plot(n_trees, oob_error_list, 'bo',\n",
    "             n_trees, oob_error_list, 'k')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Feature importance plot, modified from: \n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "top_num = 7\n",
    "forest = rf_dict[500]\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "# Sort in decreasing order:\n",
    "indices = np.argsort(importances)[::-1]\n",
    "xvarlist = X.columns[indices]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "ax = plt.gca()\n",
    "plt.title(f\"Top {top_num} feature importances\")\n",
    "plt.bar(range(top_num), importances[indices[0:top_num]])\n",
    "plt.xticks(range(top_num))\n",
    "ax.set_xticklabels(xvarlist, rotation = 45, ha='right')\n",
    "ax.set_xlabel(\"Pixel position in image\")\n",
    "ax.set_ylabel(\"Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_train = forest.predict(X)\n",
    "y_pred_train[0:5]\n",
    "\n",
    "y_pred_train_probs = pd.DataFrame(forest.predict_proba(X))\n",
    "y_pred_train_probs.head()\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y,\n",
    "                            y_pred=y_pred_train)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "class_names = list(d.values())\n",
    "\n",
    "conf_df = pd.DataFrame(conf_mat, class_names, class_names)\n",
    "conf_df\n",
    "\n",
    "\n",
    "conf_df_pct = conf_df/conf_df.sum(axis=1)\n",
    "round(conf_df_pct, 2)\n",
    "\n",
    "\n",
    "preds = list(y_pred_train)\n",
    "\n",
    "result_set = df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
